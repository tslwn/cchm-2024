\addsection{Bridging Between Quantum and Living Systems Towards Human
  Cognition and AI}[Bridging Between Quantum and Living Systems]

\sectionauthor[1]{Tomas Veloz}
\sectionauthor[2]{Olga Sobetska}
\begin{affils}
  \sectionaffil[1]{Universidad Tecnologica Metropolitana, Chile}
  \sectionaffil[2]{Centre Leo Apostel for Interdisciplinary Studies, Brije Universiteit
    Brussel}
\end{affils}

Is causality an invariant of experience?
This talk is about emergence, Self, embodiment, and goals.
Boole introduced the notion of possible experience.
There are constraints on the states of affairs that data can point to, and likewise
some things that cannot happen (cf.
Bell inequalities).
The conditions of possible experience and, relatedly, causality, have been formalized
in various ways.
See, e.g., Abramsky's formalization of Bell inequalities in databases
\parencite*{Abramsky2013}.
These formalisms imply a classical probabilistic representation, i.e., hidden
variables, which are always satisfied if experiments are performed on a single sample.
This concept is fundamental to causal reasoning, e.g., expert systems, fuzzy set and
possibility theories, Bayesian inference, and database consistency.
The conditions of possible experience are a \emph{meta-invariant} for causality.
However, there is experimental evidence that challenges the validity of these
conditions in quantum physics and cognition.

Consider the example of the conjunction fallacy, which is well-established in various
circumstances \parencites{Kahneman1972}.
\textcites{Veloz2023} give a literature review of instances of the conjunction fallacy and
visualized the differing probabilities of $A$, $B$, and $A \cap B$ that were used.
Quantum theory can model \emph{interference} between $A$ and $B$, i.e., that the
combination of the two is somehow its own entity.
Interference is maximized when you know least about the two elements individually.
They also find that these instances exhibit a consistent deviation from rational
(classical) expectations, with differing forms of the de Morgan laws.

What about an `emergentist' approach to machine learning, that centres agency,
autonomy, and goal-directedness?
The dominant paradigm in ML is that optimization is a defining feature of the notion of
`goal', but the process of configuring goals is not considered.
Goals are intrinsic to the self but intimately related to environmental interactions.
These interactions explain the emergent complexity of goals.
Autopoeisis (self-creation).
The idea of affordances: an entity has a particular structure, which can \emph{afford}
reality in a particular way, and has certain goals.
A faculty of this nature implies dangers and related objectives.

Complex adaptive systems, and the example of chemical organization theory.
In order for something to be, it has to be stable (self-maintaining).
The network needs to be closed, i.e., the things that it produces must be part of the
same network.
Stationary states of such a system are organizations, and its structural dynamics are
movements between organizations, triggered by perturbations.
The set of organizations is a partially-ordered set.
How does such a set evolve?
Random walk over structures and the possibility of stable structures developing
\parencites{Veloz2023a}.
Resilience to perturbations and the basis of a more `constructivist' theory of
cognition.

Nietzsche's three transformations of the human spirit, for the AI era.
The evolution of self-producing complex adaptive systems provides a framework to
explain the emergence of purposeful intelligence.
Can mathematics from quantum theory help to explain this emergence?
